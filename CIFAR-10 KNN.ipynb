{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(path):\n",
    "    listOfFiles = os.listdir(path='cifar-10-batches-py/')\n",
    "    train = []\n",
    "    train_labels = []\n",
    "        \n",
    "        \n",
    "    print(\"Training files = \",listOfFiles[1:6])\n",
    "    # collecting Training data from cifar10:\n",
    "    for file in listOfFiles[1:6]:\n",
    "        with open(path+file,'rb') as fo:\n",
    "            dict = pickle.load(fo,encoding='bytes')\n",
    "            train.append(dict[b'data'])\n",
    "            train_labels.append(dict[b'labels'])\n",
    "\n",
    "    dictData = {}\n",
    "    dictData['train_data'] = np.reshape(np.array(train),newshape=(np.array(train).shape[0]*np.array(train).shape[1],np.array(train).shape[2]))\n",
    "    dictData['train_labels'] = np.reshape(np.array(train_labels),newshape=(np.array(train_labels).shape[0]*np.array(train_labels).shape[1]))\n",
    "    return dictData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files =  ['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5']\n"
     ]
    }
   ],
   "source": [
    "#load the dataset\n",
    "#Show training files\n",
    "dataset = loadData(path='cifar-10-batches-py/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collect 50000 data\n",
    "dataset['train_data'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show random train sample\n",
    "temp = dataset['train_data'][20000]\n",
    "label = dataset['train_labels'][20000]\n",
    "# Since every row represents one example to re-map it to image we have to form three 32,32 matrix,\n",
    "#representing with RGB values\n",
    "\n",
    "R = temp[0:1024].reshape(32,32)\n",
    "G = np.reshape(temp[1024:2048],newshape=(32,32))\n",
    "B = np.reshape(temp[2048:],newshape=(32,32))\n",
    "temp = np.dstack((R,G,B))   #for stacking all these 32,32 matrices.\n",
    "plt.imshow(temp)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel(label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train= dataset['train_data'],dataset['train_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the actual classifier:\n",
    "#inputs will be of shape N X F where N = number of examples and F = number of features for each image.\n",
    "#labels will be of size N,1. This consists of labels for all N labels from 10 classes\n",
    "\n",
    "class kNearestNeighbour(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self,X,Y):\n",
    "        #Knn will remember all of its training data\n",
    "        self.Xtr = X\n",
    "        self.Ytr = Y\n",
    "        \n",
    "    def predict(self,X,k):\n",
    "        #to get no. of samples in train set \n",
    "        test_samples = X.shape[0]\n",
    "        Ypred = np.zeros(test_samples,dtype=self.Ytr.dtype)\n",
    "        \n",
    "        #Calculating the l1 distance between current samples of test and train set\n",
    "        for i in range(test_samples):\n",
    "            \n",
    "            print(\"Test sample = \",i,end=\"\\r\")\n",
    "            #label_count is array of zeros used to store the count for each class while comparing neighbours\n",
    "            label_count = np.zeros(10,dtype=self.Ytr.dtype)    \n",
    "            dist = np.sum(np.abs(X[i,:] - self.Xtr),axis=1)   #take the absolute sum horizontally across columns\n",
    "            \n",
    "            \n",
    "            #idx will contain k smallest indices at the start of the list\n",
    "            #this is called partial sorting for more information look: https://docs.scipy.org/doc/numpy/reference/generated/numpy.argpartition.html\n",
    "            #min_ind will help us to slice through k indices which have minimum distance\n",
    "            idx = np.argpartition(dist,k)\n",
    "            min_ind = idx[:k]\n",
    "            \n",
    "            #This for loop iterates over min_ind and find the label present in train-set_Y for x\n",
    "            #and increase the count at that particular index whenever any label is repeated.\n",
    "            #Max value at any index is returned using np.argmax() and stored at ith index of Ypred i.e. predicted values\n",
    "            for x in min_ind:\n",
    "                label_count[int(self.Ytr[x])] +=1\n",
    "            Ypred[i] = np.argmax(label_count)\n",
    "    \n",
    "    \n",
    "        return Ypred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 0\n",
      "k =  1\n",
      "Test sample =  9999\n",
      "\n",
      "k =  2\n",
      "Test sample =  9999\n",
      "\n",
      "k =  3\n",
      "Test sample =  9999\n",
      "\n",
      "k =  4\n",
      "Test sample =  9999\n",
      "\n",
      "k =  5\n",
      "Test sample =  9999\n",
      "\n",
      "k =  6\n",
      "Test sample =  24\r"
     ]
    }
   ],
   "source": [
    "#Splitting the data into 5 equal folds\n",
    "num_folds = 5\n",
    "num_training = 50000\n",
    "#k cjoice 1 to 20 its take long time for run\n",
    "k_choices = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "\n",
    "# Check that training set can be equally divided into num_folds portions\n",
    "if num_training/num_folds % num_folds != 0.0:\n",
    "    raise ValueError('training samples cant evenly divisible by folds.')\n",
    "\n",
    "# Split training set into num_folds lists\n",
    "X_train_folds = np.split(X_train, num_folds)\n",
    "y_train_folds = np.split(y_train, num_folds)\n",
    "\n",
    "# A dictionary holding the accuracies for different values of k that we find\n",
    "# when running cross-validation. After running cross-validation,\n",
    "# k_to_accuracies[k] should be a list of length num_folds giving the different\n",
    "# accuracy values that we found when using that value of k.\n",
    "k_to_accuracies = {}\n",
    "\n",
    "# Perform k-fold cross validation to find the best value of k\n",
    "# Loop over num_folds in outer loop to reuse computed distances for all values of k\n",
    "for k in k_choices:\n",
    "    k_to_accuracies[k] = []\n",
    "    \n",
    "for idx in range(num_folds):\n",
    "    print(\"Fold :\", idx)\n",
    "    # Use bin with index idx as validation set, rest as training set \n",
    "    X_train_set = np.concatenate((*X_train_folds[:idx], *X_train_folds[idx+1:]), axis=0)\n",
    "    y_train_set = np.concatenate((*y_train_folds[:idx], *y_train_folds[idx+1:]), axis=0)\n",
    "    X_validation_set = X_train_folds[idx]\n",
    "    y_validation_set = y_train_folds[idx]   \n",
    "    num_validation_set = X_validation_set.shape[0]\n",
    "    # Train kNN classifier\n",
    "    knn = kNearestNeighbour()\n",
    "    knn.train(X_train_set, y_train_set)\n",
    "\n",
    "    \n",
    "    for k in k_choices:\n",
    "        print(\"k = \",k,end=\"\\n\")\n",
    "        # Predict labels for validation set\n",
    "        y_validation_pred = knn.predict(X_validation_set,k)\n",
    "        # Check accuracy for validation set\n",
    "        accuracy = np.mean(y_validation_pred==y_validation_set)\n",
    "        k_to_accuracies[k].append(accuracy)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Print out the computed accuracies\n",
    "for k in sorted(k_to_accuracies):\n",
    "    for accuracy in k_to_accuracies[k]:\n",
    "        print('k = %d, accuracy = %f' % (k, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the raw observations\n",
    "for k in k_choices:\n",
    "    accuracies = k_to_accuracies[k]\n",
    "    print('k = %d, average accuracy = %f' % (k, np.average(accuracies)))\n",
    "    plt.scatter([k] * len(accuracies), accuracies)\n",
    "\n",
    "# plot the trend line with error bars that correspond to standard deviation\n",
    "accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
    "plt.title('Cross-validation on k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
